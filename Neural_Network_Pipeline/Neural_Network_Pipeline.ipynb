{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I have built a neural network using keras that uses a sklearn pipeline. The data that is used for this example is quite simple so the pipeline is only used for scaling but the pipeline can also be used for encoding categorical features and many other purposes. The data can be found on the [UCI](http://archive.ics.uci.edu/ml/datasets/HIGGS) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using plaidml to connect to my eGPU\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.000000000000000000e+00</th>\n",
       "      <th>8.692932128906250000e-01</th>\n",
       "      <th>-6.350818276405334473e-01</th>\n",
       "      <th>2.256902605295181274e-01</th>\n",
       "      <th>3.274700641632080078e-01</th>\n",
       "      <th>-6.899932026863098145e-01</th>\n",
       "      <th>7.542022466659545898e-01</th>\n",
       "      <th>-2.485731393098831177e-01</th>\n",
       "      <th>-1.092063903808593750e+00</th>\n",
       "      <th>0.000000000000000000e+00</th>\n",
       "      <th>...</th>\n",
       "      <th>-1.045456994324922562e-02</th>\n",
       "      <th>-4.576716944575309753e-02</th>\n",
       "      <th>3.101961374282836914e+00</th>\n",
       "      <th>1.353760004043579102e+00</th>\n",
       "      <th>9.795631170272827148e-01</th>\n",
       "      <th>9.780761599540710449e-01</th>\n",
       "      <th>9.200048446655273438e-01</th>\n",
       "      <th>7.216574549674987793e-01</th>\n",
       "      <th>9.887509346008300781e-01</th>\n",
       "      <th>8.766783475875854492e-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.595839</td>\n",
       "      <td>-0.607811</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>1.818450</td>\n",
       "      <td>-0.111906</td>\n",
       "      <td>0.847550</td>\n",
       "      <td>-0.566437</td>\n",
       "      <td>1.581239</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654227</td>\n",
       "      <td>-1.274345</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.823761</td>\n",
       "      <td>0.938191</td>\n",
       "      <td>0.971758</td>\n",
       "      <td>0.789176</td>\n",
       "      <td>0.430553</td>\n",
       "      <td>0.961357</td>\n",
       "      <td>0.957818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1.000000000000000000e+00  8.692932128906250000e-01  \\\n",
       "0                       1.0                  0.907542   \n",
       "1                       1.0                  0.798835   \n",
       "2                       0.0                  1.344385   \n",
       "3                       1.0                  1.105009   \n",
       "4                       0.0                  1.595839   \n",
       "\n",
       "   -6.350818276405334473e-01  2.256902605295181274e-01  \\\n",
       "0                   0.329147                  0.359412   \n",
       "1                   1.470639                 -1.635975   \n",
       "2                  -0.876626                  0.935913   \n",
       "3                   0.321356                  1.522401   \n",
       "4                  -0.607811                  0.007075   \n",
       "\n",
       "   3.274700641632080078e-01  -6.899932026863098145e-01  \\\n",
       "0                  1.497970                  -0.313010   \n",
       "1                  0.453773                   0.425629   \n",
       "2                  1.992050                   0.882454   \n",
       "3                  0.882808                  -1.205349   \n",
       "4                  1.818450                  -0.111906   \n",
       "\n",
       "   7.542022466659545898e-01  -2.485731393098831177e-01  \\\n",
       "0                  1.095531                  -0.557525   \n",
       "1                  1.104875                   1.282322   \n",
       "2                  1.786066                  -1.646778   \n",
       "3                  0.681466                  -1.070464   \n",
       "4                  0.847550                  -0.566437   \n",
       "\n",
       "   -1.092063903808593750e+00  0.000000000000000000e+00  ...  \\\n",
       "0                  -1.588230                  2.173076  ...   \n",
       "1                   1.381664                  0.000000  ...   \n",
       "2                  -0.942383                  0.000000  ...   \n",
       "3                  -0.921871                  0.000000  ...   \n",
       "4                   1.581239                  2.173076  ...   \n",
       "\n",
       "   -1.045456994324922562e-02  -4.576716944575309753e-02  \\\n",
       "0                  -1.138930                  -0.000819   \n",
       "1                   1.128848                   0.900461   \n",
       "2                  -0.678379                  -1.360356   \n",
       "3                  -0.373566                   0.113041   \n",
       "4                  -0.654227                  -1.274345   \n",
       "\n",
       "   3.101961374282836914e+00  1.353760004043579102e+00  \\\n",
       "0                  0.000000                  0.302220   \n",
       "1                  0.000000                  0.909753   \n",
       "2                  0.000000                  0.946652   \n",
       "3                  0.000000                  0.755856   \n",
       "4                  3.101961                  0.823761   \n",
       "\n",
       "   9.795631170272827148e-01  9.780761599540710449e-01  \\\n",
       "0                  0.833048                  0.985700   \n",
       "1                  1.108330                  0.985692   \n",
       "2                  1.028704                  0.998656   \n",
       "3                  1.361057                  0.986610   \n",
       "4                  0.938191                  0.971758   \n",
       "\n",
       "   9.200048446655273438e-01  7.216574549674987793e-01  \\\n",
       "0                  0.978098                  0.779732   \n",
       "1                  0.951331                  0.803252   \n",
       "2                  0.728281                  0.869200   \n",
       "3                  0.838085                  1.133295   \n",
       "4                  0.789176                  0.430553   \n",
       "\n",
       "   9.887509346008300781e-01  8.766783475875854492e-01  \n",
       "0                  0.992356                  0.798343  \n",
       "1                  0.865924                  0.780118  \n",
       "2                  1.026736                  0.957904  \n",
       "3                  0.872245                  0.808487  \n",
       "4                  0.961357                  0.957818  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas and numpy to work with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and read data file\n",
    "data=pd.read_csv('HIGGS.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "y_train = x_train['1.000000000000000000e+00']\n",
    "y_test = x_test['1.000000000000000000e+00']\n",
    "\n",
    "x_train = x_train.drop(['1.000000000000000000e+00'], axis=1)\n",
    "x_test = x_test.drop(['1.000000000000000000e+00'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Build Neural Network\n",
    "def nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=x_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Build Pipeline for scaling data\n",
    "estimators = []\n",
    "estimators.append(('ss', preprocessing.StandardScaler()))\n",
    "estimators.append(('nn', KerasClassifier(build_fn=nn, epochs=1, batch_size=128)))\n",
    "pipeline = pipeline.Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "8799999/8799999 [==============================] - 319s 36us/step - loss: 0.5322 - acc: 0.7305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('ss', StandardScaler(copy=True, with_mean=True, with_std=True)), ('nn', <keras.wrappers.scikit_learn.KerasClassifier object at 0x121809550>)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model did not end up with a very high prediction accuracy but that was not the point of the notebook. The point of the notebook was to use the sklearn pipeline with a keras neural network and the pipeline worked well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
