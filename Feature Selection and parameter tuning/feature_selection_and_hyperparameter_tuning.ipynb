{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Hyperperameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will use a dataset from [kaggle]('https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star') to try and find the best model for predicting pulsar stars. I will do this by selecting the best features and then by tuning hyperperameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1          2         3         4         5          6          7  \\\n",
       "0  140.562500  55.683782 -0.234571 -0.699648  3.199833  19.110426   7.975532   \n",
       "1  102.507812  58.882430  0.465318 -0.515088  1.677258  14.860146  10.576487   \n",
       "2  103.015625  39.341649  0.323328  1.051164  3.121237  21.744669   7.735822   \n",
       "3  136.750000  57.178449 -0.068415 -0.636238  3.642977  20.959280   6.896499   \n",
       "4   88.726562  40.672225  0.600866  1.123492  1.178930  11.468720  14.269573   \n",
       "\n",
       "            8  class  \n",
       "0   74.242225      0  \n",
       "1  127.393580      0  \n",
       "2   63.171909      0  \n",
       "3   53.593661      0  \n",
       "4  252.567306      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file into a pandas dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stars = pd.read_csv('HTRU_2.csv',  \n",
    "                  names=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"class\"])\n",
    "\n",
    "stars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn negative numbers into NAN\n",
    "stars = stars[stars >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAN values\n",
    "stars = stars.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train/test sets as well as feature and label dataframes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test = train_test_split(stars, test_size=0.2)\n",
    "\n",
    "y_train = x_train['class']\n",
    "y_test = x_test['class']\n",
    "\n",
    "x_train=x_train.drop(['class'], axis=1)\n",
    "x_test=x_test.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I will use selectkbest to find the features that will be the best predictors for the labels which will lead to a better model and faster training time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.22069817e-01 3.16471572e+00 6.75923744e+01]\n",
      " [2.73274451e+00 3.91354515e+01 1.36942577e+00]\n",
      " [6.68161838e-01 7.00501672e+00 2.37320597e+01]\n",
      " [2.03404680e+01 1.46530100e+01 1.14409955e+01]\n",
      " [1.99916994e-01 2.93143813e+00 9.47097486e+01]\n",
      " [6.61009395e-01 2.12541806e+00 1.21746158e+02]\n",
      " [1.09159462e-01 6.89799331e-01 3.63471664e+02]\n",
      " [6.43726530e-01 3.70150502e+00 5.65603488e+01]\n",
      " [4.08896980e+00 2.22993311e+01 4.24387489e+00]\n",
      " [8.01163159e-01 2.06354515e+00 1.82066055e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Here I am searching for the three best predictors out the eight features. \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "x_train_best=SelectKBest(score_func=chi2,k=3).fit_transform(x_train,y_train)\n",
    "print(x_train_best[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                1          2         3          4          5          6  \\\n",
      "8419   107.609375  44.675083  0.184331   0.222070   3.164716  23.471511   \n",
      "9037    82.218750  49.904274  1.610495   2.732745  39.135452  72.729627   \n",
      "3121   118.078125  41.883322  0.125735   0.668162   7.005017  30.025435   \n",
      "3243    49.007812  32.512377  3.953519  20.340468  14.653010  46.732418   \n",
      "3274   126.945312  46.491987  0.151432   0.199917   2.931438  14.698940   \n",
      "4653    99.320312  42.363002  0.650448   0.661009   2.125418  14.520174   \n",
      "10247  130.937500  48.955616  0.005734   0.109159   0.689799  11.089101   \n",
      "2503   114.609375  43.190211  0.018183   0.643727   3.701505  25.605974   \n",
      "7097    88.773438  32.705890  0.758555   4.088970  22.299331  62.944904   \n",
      "11926  113.062500  45.729632  0.353996   0.801163   2.063545  13.094370   \n",
      "\n",
      "               7           8  \n",
      "8419    8.099852   67.592374  \n",
      "9037    1.684183    1.369426  \n",
      "3121    4.748131   23.732060  \n",
      "3243    3.470588   11.440995  \n",
      "3274    8.144680   94.709749  \n",
      "4653    9.867825  121.746158  \n",
      "10247  18.442803  363.471664  \n",
      "2503    7.445691   56.560349  \n",
      "7097    2.486482    4.243875  \n",
      "11926  11.721295  182.066055  \n"
     ]
    }
   ],
   "source": [
    "# Print out all features to find that the three best features form above are 4, 5 and eight\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "    print(x_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with the three best features\n",
    "\n",
    "new_stars = stars[['4', '5', '8', 'class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I will use cross validation to predict pulsar stars. Cross validation is useful because the datasets are broken down into smaller pieces which are each used for training and testing which helps cut down the variance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test = train_test_split(new_stars, test_size=0.2)\n",
    "y_train = x_train['class']\n",
    "y_test = x_test['class']\n",
    "\n",
    "x_train=x_train.drop(['class'], axis=1)\n",
    "x_test=x_test.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature data using standard scalar to make the model more efficient\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "feature_scaler = StandardScaler()  \n",
    "x_train = feature_scaler.fit_transform(x_train)  \n",
    "x_test = feature_scaler.transform(x_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the random forest classifier and create an object\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "classifier = RandomForestClassifier(n_estimators=300, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation on the dataset for five folds\n",
    "\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "all_accuracies = cross_val_score(estimator=classifier, X=x_train, y=y_train, cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95031491 0.96431071 0.96078431 0.95868347 0.96426069]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracies of the five folds\n",
    "print(all_accuracies)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596708172373164\n"
     ]
    }
   ],
   "source": [
    "# Print mean of the five folds\n",
    "print(all_accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005144769838290858\n"
     ]
    }
   ],
   "source": [
    "# Print the standard deviation of the five folds\n",
    "print(all_accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gird Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search will help find the optimal hyperparameters for the model so we can avoid guessing and checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of parameters that are being tested testing\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_param = {  \n",
    "    'n_estimators': [100, 300, 500, 800, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search class\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=classifier,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 300, 500, 800, 1000], 'criterion': ['gini', 'entropy'], 'bootstrap': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the class to our data from before\n",
    "\n",
    "gd_sr.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'entropy', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Print out the results for the best model parameters\n",
    "best_parameters = gd_sr.best_params_  \n",
    "print(best_parameters)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9605097325304579\n"
     ]
    }
   ],
   "source": [
    "# Print best accuracy\n",
    "best_result = gd_sr.best_score_  \n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
